{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "N3Gj65LZeUE7",
      "metadata": {
        "id": "N3Gj65LZeUE7"
      },
      "source": [
        "# Install datasets\n",
        "Restart runtime after installing libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J-kn_mVreWZx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-kn_mVreWZx",
        "outputId": "4252dfb9-6612-4627-a0ed-8938cf6b3dfd"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5f8e70a",
      "metadata": {
        "id": "d5f8e70a"
      },
      "source": [
        "# Download dataset and model\n",
        "Download dataset from huggingface or get local dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b9bb36-d602-4f09-af76-942271cb2253",
      "metadata": {
        "id": "61b9bb36-d602-4f09-af76-942271cb2253",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# download alpaca dataset \n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"tatsu-lab/alpaca\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946fd81f-0dbe-4868-b691-1a35b4f2741a",
      "metadata": {
        "id": "946fd81f-0dbe-4868-b691-1a35b4f2741a",
        "outputId": "aff6f47f-6d9f-4719-d624-447f99b4f808"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f98aca9-3ee9-4c72-a13d-c7d6978ae435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "5f64bf6a50fe4a3e8b06833a034b7589",
            "5c885597d2804ec798d21cc6cf6cfc23",
            "75e77b0b616e4208aaff21f09fd08056",
            "021cc04dcaea4684b7f25e019e52d7a8",
            "1fdfd16355354fd5a61e7ba93da2a8be",
            "bba4859d442f4fa69fb17f009f3f83b1",
            "80a1fa4029484dbeb1da3d7f445b5500",
            "c3cb96f47d2f45aab4a5249d316dd237",
            "474a0f6075514f4eb938354c75cb51ab",
            "3deae4de694a46f8a8e5fb844685b935",
            "e937bb00a17540a6b3143313090051ea"
          ]
        },
        "id": "7f98aca9-3ee9-4c72-a13d-c7d6978ae435",
        "outputId": "153ee794-6356-4980-a540-8f6ea781c63b"
      },
      "outputs": [],
      "source": [
        "# download model \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForCausalLM, IntervalStrategy\n",
        "\n",
        "torch.manual_seed(42)\n",
        "output_dir = \"EleutherAI/gpt-neo-125m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir, bos_token='<|startoftext|>',\n",
        "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "model = AutoModelForCausalLM.from_pretrained(output_dir, low_cpu_mem_usage=True, device_map=\"auto\")  \n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d3f31f",
      "metadata": {
        "id": "d2d3f31f"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04d1a20-b06e-4bd8-abca-70d0500f1670",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "a04d1a20-b06e-4bd8-abca-70d0500f1670",
        "outputId": "471f8736-7bd2-4b11-975c-4f9a7b1ab354"
      },
      "outputs": [],
      "source": [
        "dataset = dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pp0hxKeQggtJ",
      "metadata": {
        "id": "pp0hxKeQggtJ"
      },
      "outputs": [],
      "source": [
        "# format dataset \n",
        "data_list = []\n",
        "text = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\"\n",
        "for i in len(dataset['instruction']):\n",
        "    if dataset['input']:\n",
        "        temp = text + \"###Instruction:\" + dataset['instruction'][i] + \"\\n\\n###Input:\" + dataset['input'][i] + \"\\n\\n###Output:\" + dataset['output'][i]\n",
        "    else:\n",
        "        temp = text + \"###Instruction:\" + dataset['instruction'][i] + \"\\n\\n###Output:\" + dataset['output'][i]\n",
        "    data_list.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0978ad9-7a00-428b-86e8-dfa962a5f694",
      "metadata": {
        "id": "e0978ad9-7a00-428b-86e8-dfa962a5f694"
      },
      "outputs": [],
      "source": [
        "data_list = pd.Series(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520ddb4e-e79c-42b4-9be2-96d56a336fcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "520ddb4e-e79c-42b4-9be2-96d56a336fcd",
        "outputId": "c9f677fd-9c3f-4f97-be14-ed75d76ac418"
      },
      "outputs": [],
      "source": [
        "data_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cbe4d1c-2be3-42bf-b59b-1bd8a15c0214",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cbe4d1c-2be3-42bf-b59b-1bd8a15c0214",
        "outputId": "7e4e124a-6502-49bc-c8df-171d90a6de65"
      },
      "outputs": [],
      "source": [
        "len(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c096bb9b-5515-4181-8aae-486c18672d8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c096bb9b-5515-4181-8aae-486c18672d8d",
        "outputId": "a44d9352-4728-454c-8b76-e314648f8adb"
      },
      "outputs": [],
      "source": [
        "# find longest sequence \n",
        "max_length = max([len(tokenizer.encode(e)) for e in data_list])\n",
        "print(\"Max length: {}\".format(max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fda6d8-3a86-4aa5-8fac-755f24b10f51",
      "metadata": {
        "id": "08fda6d8-3a86-4aa5-8fac-755f24b10f51"
      },
      "outputs": [],
      "source": [
        "# class to tokenize and add attention mask to dataset  \n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        for txt in txt_list:\n",
        "            encodings_dict = tokenizer(f\"<|startoftext|>\"+ txt + \"<|endoftext|>\", truncation=True,\n",
        "                                       max_length=max_length, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dfe80ec-a1a4-4cba-b2fc-5f6c7d993d86",
      "metadata": {
        "id": "5dfe80ec-a1a4-4cba-b2fc-5f6c7d993d86"
      },
      "outputs": [],
      "source": [
        "mydataset = MyDataset(data_list, tokenizer, max_length = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900d89a0-9721-42ee-a811-e7ed28465586",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "900d89a0-9721-42ee-a811-e7ed28465586",
        "outputId": "40e864c4-d66f-44d2-ef89-a69b926c1dad"
      },
      "outputs": [],
      "source": [
        "mydataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c923f0b",
      "metadata": {
        "id": "4c923f0b"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c96e83-75f4-4f27-a422-d90471c810d1",
      "metadata": {
        "id": "93c96e83-75f4-4f27-a422-d90471c810d1"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from transformers import DataCollatorForLanguageModeling, AutoConfig, default_data_collator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb86538-c493-42b6-8c1b-9de2c5c4ee5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "abb86538-c493-42b6-8c1b-9de2c5c4ee5e",
        "outputId": "a8e21c4e-fadc-47d8-cb8f-81faef0202ac"
      },
      "outputs": [],
      "source": [
        "use_fp16 = True  # True if you're using mixed precision\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"finetune_save\",  # model save path \n",
        "    optim=\"adafactor\", # uses less memory \n",
        "    num_train_epochs=1,  # number of train epochs \n",
        "    per_device_train_batch_size=2,  # batch size \n",
        "    fp16=use_fp16,  # whether to use mixed precision \n",
        "    learning_rate=5e-5,  # learning rate determines the size of the steps taken during the optimization process\n",
        "    logging_strategy=\"steps\",  # print log with steps \n",
        "    warmup_steps=3000,  # initial phase where the learning rate is gradually increased from a small value to its intended value\n",
        "    weight_decay=0.01,  # regularization technique used \n",
        "    logging_steps=0.1,  # percentage of steps being updated \n",
        "    save_steps=0.06, # save model, decimals is percent and integer is number of steps\n",
        "    save_strategy=\"steps\",  # save model according to steps or epoch \n",
        "    report_to=\"none\"  \n",
        ")\n",
        "\n",
        "if use_fp16:\n",
        "    scaler = GradScaler()  # prevent underflow\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=mydataset,\n",
        "    data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
        "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
        "                                                              'labels': torch.stack([f[0] for f in data])})\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8ca258-fa69-499d-bb30-e906bef3df4b",
      "metadata": {
        "id": "ce8ca258-fa69-499d-bb30-e906bef3df4b"
      },
      "source": [
        "# Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e64a572-c37b-4b22-b623-a3edc42f1df7",
      "metadata": {
        "id": "7e64a572-c37b-4b22-b623-a3edc42f1df7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(output_dir, torch_dtype=torch.float16, low_cpu_mem_usage=True).to(device=f\"cuda\", non_blocking=True)  # use mixed precision "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1447430f-8246-4cd4-b5e2-fe29f6090031",
      "metadata": {
        "id": "1447430f-8246-4cd4-b5e2-fe29f6090031"
      },
      "source": [
        "# Load Dataset again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18db446-89a7-49c1-b332-3703fde8187d",
      "metadata": {
        "id": "a18db446-89a7-49c1-b332-3703fde8187d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
        "dataset = dataset['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9092ecec-94eb-4422-9c0b-f08f240f83c4",
      "metadata": {
        "id": "9092ecec-94eb-4422-9c0b-f08f240f83c4"
      },
      "source": [
        "# Generate 1\n",
        "Generate from model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee26623-fc7e-4601-be58-2541de070a66",
      "metadata": {
        "id": "6ee26623-fc7e-4601-be58-2541de070a66"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "text = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\"\n",
        "if dataset['input'][i]:\n",
        "    temp = text + \"###Instruction:\" + dataset['instruction'][i] + \"\\n\\n###Input:\" + dataset['input'][i] + \"\\n\\n###Output:\"\n",
        "else:\n",
        "    temp = text + \"###Instruction:\" + dataset['instruction'][i] + \"\\n\\n###Output:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d4a6ef-7156-434b-b8ac-a6e730c21861",
      "metadata": {
        "id": "b1d4a6ef-7156-434b-b8ac-a6e730c21861",
        "outputId": "b7557c9e-9113-43e6-9bf8-1a47e80b34c4"
      },
      "outputs": [],
      "source": [
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276785f2-4b8c-4b60-bc44-62d137716716",
      "metadata": {
        "id": "276785f2-4b8c-4b60-bc44-62d137716716",
        "outputId": "4321ba9d-589f-45f9-ecae-d0585dd29a9c"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = \"[PAD]\"\n",
        "tokenizer.padding_side = \"left\"\n",
        "generated = tokenizer(\"<|startoftext|>\" + temp, return_tensors=\"pt\").input_ids.cuda()\n",
        "sample_outputs = model.generate(generated, do_sample=True, # can use hyperparameters if set True\n",
        "                                          top_k=50, # choose from the top k words while generating \n",
        "                                          top_p=0.95 # choose from top p% words while generating\n",
        "                                          min_length=20, # minimum generation length\n",
        "                                          max_length=300, # maximum generation length\n",
        "                                          temperature=1.0, # higher likelihood of generating low-probability words, likely to get unpredictable responses\n",
        "                                          num_return_sequences=5 # generate n question-answer sets \n",
        "                        ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7174a24-3d5a-410e-ad6e-4620fd1732f1",
      "metadata": {
        "id": "b7174a24-3d5a-410e-ad6e-4620fd1732f1",
        "outputId": "7ece61e2-14b1-4543-bfa4-80b6247e48f0"
      },
      "outputs": [],
      "source": [
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {} \\n\".format(i, tokenizer.decode(\n",
        "        sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7766f4e-ee02-49f3-9f64-707e34108df4",
      "metadata": {
        "id": "a7766f4e-ee02-49f3-9f64-707e34108df4"
      },
      "source": [
        "# Generate 2\n",
        "Generate using pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2436e5-0508-407f-b078-8c6964081d41",
      "metadata": {
        "id": "ea2436e5-0508-407f-b078-8c6964081d41"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9039f7f8-9ebc-48c4-bb1e-cb25e6093534",
      "metadata": {
        "id": "9039f7f8-9ebc-48c4-bb1e-cb25e6093534",
        "outputId": "e8438387-5462-4466-fcc6-2229f07f8ce9"
      },
      "outputs": [],
      "source": [
        "response = generator(temp, do_sample=True, # can use hyperparameters if set True\n",
        "\t\t\t\t\t\t\ttop_k=50, # choose from the top k words while generating \n",
        "                            top_p=0.95 # choose from top p% words while generating\n",
        "\t\t\t\t\t\t    min_length=20, # minimum generation length\n",
        "\t\t\t\t\t\t\tmax_length=300, # maximum generation length\n",
        "\t\t\t\t\t\t\ttemperature=1.0, # higher likelihood of generating low-probability words, likely to get unpredictable responses\n",
        "                            return_full_text=True\n",
        "\t\t\t\t\t)\n",
        "print(response[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeabf27b-9816-4fb7-854d-2528155fbc75",
      "metadata": {
        "id": "aeabf27b-9816-4fb7-854d-2528155fbc75"
      },
      "source": [
        "# Upload to Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54133fa6-5656-48a9-87d2-f4747596c10b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "04d2894fadc84276835b9f6f74850321"
          ]
        },
        "id": "54133fa6-5656-48a9-87d2-f4747596c10b",
        "outputId": "602cc637-29b3-4f63-83d3-eddf1eb1f472"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eaf9009",
      "metadata": {},
      "outputs": [],
      "source": [
        "huggingface_path = \"huggingfaceid/repositoryname\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e21a3b-624f-44d5-b2f9-ace085edca3f",
      "metadata": {
        "id": "b7e21a3b-624f-44d5-b2f9-ace085edca3f",
        "outputId": "5bc8bdb2-5f2f-41e5-902b-6d29abc416d2"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(huggingface_path)\n",
        "model.push_to_hub(huggingface_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d763efe4-2d1b-42de-81aa-cd36b24c4916",
      "metadata": {
        "id": "d763efe4-2d1b-42de-81aa-cd36b24c4916"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "021cc04dcaea4684b7f25e019e52d7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3deae4de694a46f8a8e5fb844685b935",
            "placeholder": "​",
            "style": "IPY_MODEL_e937bb00a17540a6b3143313090051ea",
            "value": " 526M/526M [00:11&lt;00:00, 41.5MB/s]"
          }
        },
        "1fdfd16355354fd5a61e7ba93da2a8be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3deae4de694a46f8a8e5fb844685b935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474a0f6075514f4eb938354c75cb51ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c885597d2804ec798d21cc6cf6cfc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba4859d442f4fa69fb17f009f3f83b1",
            "placeholder": "​",
            "style": "IPY_MODEL_80a1fa4029484dbeb1da3d7f445b5500",
            "value": "model.safetensors: 100%"
          }
        },
        "5f64bf6a50fe4a3e8b06833a034b7589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c885597d2804ec798d21cc6cf6cfc23",
              "IPY_MODEL_75e77b0b616e4208aaff21f09fd08056",
              "IPY_MODEL_021cc04dcaea4684b7f25e019e52d7a8"
            ],
            "layout": "IPY_MODEL_1fdfd16355354fd5a61e7ba93da2a8be"
          }
        },
        "75e77b0b616e4208aaff21f09fd08056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3cb96f47d2f45aab4a5249d316dd237",
            "max": 525979192,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474a0f6075514f4eb938354c75cb51ab",
            "value": 525979192
          }
        },
        "80a1fa4029484dbeb1da3d7f445b5500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba4859d442f4fa69fb17f009f3f83b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cb96f47d2f45aab4a5249d316dd237": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e937bb00a17540a6b3143313090051ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
